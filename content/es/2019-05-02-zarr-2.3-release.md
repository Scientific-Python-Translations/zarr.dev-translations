---
title: Versión 2.3 de Zarr Python
date: 2019-05-23
categories: lanzamiento zarr python
layout: home
author_profile: false
sidebar:
  title: Contenido
  nav: sidebar
---

Recientemente lanzamos la versión 2.3 del [paquete Python Zarr](https://zarr.readthedocs.io/en/stable/), que implementa el protocolo Zarr para almacenar matrices tipadas N-dimensionales y está diseñado para su uso en computación distribuida y paralela. Esta publicación proporciona una descripción general de las nuevas funciones de esta versión y alguna información sobre las direcciones futuras de Zarr.

## Nuevas opciones de almacenamiento para computación distribuida y en la nube

Una característica clave del protocolo Zarr es que el sistema de almacenamiento subyacente está desacoplado de otros componentes a través de una simple interfaz llave/valor. En Python, esta interfaz corresponde a la [`interfaz MutableMapping`](https://docs.python.org/3/glossary.html#term-mapping), que es la interfaz que implementa los diccionarios de Python [`dict`](https://docs.python.org/3/library/stdtypes.html#dict). Es decir, cualquier cosa parecida a un `dict` se puede utilizar para almacenar datos de Zarr. La simplicidad de esta interfaz significa que es relativamente sencillo agregar soporte para una variedad de sistemas de almacenamiento diferentes. La versión 2.3 agrega soporte para almacenamiento usando [SQLite](https://zarr.readthedocs.io/en/stable/api/storage.html#zarr.storage.SQLiteStore), Redis, MongoDB y [Azure Blob Storage](https://zarr.readthedocs.io/en/stable/api/storage.html#zarr.storage.ABSStore).

Por ejemplo, aquí hay un código que crea una matriz usando MongoDB:

{% highlight python %}
import zarr
store = zarr.MongoDBStore('localhost')
root = zarr.group(store=store, overwrite=True)
foo = bar.create_group('foo')
bar = foo.create_dataset('bar', shape=(10000, 1000), chunks=(1000, 100))
bar[:] = 42
store.close()
{% endhighlight %}

Para hacer lo mismo pero almacenando los datos en la nube a través de Azure Blob Storage, reemplace la creación de instancias del objeto `store` con:

{% highlight python %}
store = zarr.ABSStore(container='test', account_name='foo', account_key='bar')
{% endhighlight %}

La compatibilidad con otros servicios de almacenamiento de objetos en la nube ya estaba disponible a través de otros paquetes, con Amazon S3 compatible con el paquete [s3fs](http://s3fs.readthedocs.io/en/latest/) y Google Cloud Storage compatible con el paquete [gcsfs](https://gcsfs.readthedocs.io/en/latest/). Hay más notas sobre el uso del almacenamiento en la nube disponibles en el [tutorial de Zarr](https://zarr.readthedocs.io/en/stable/tutorial.html#distributed-cloud-storage).

El atractivo del almacenamiento en la nube es que el ancho de banda total de Entrada/Salida aumenta linealmente con el tamaño de un clúster informático, por lo que no existen límites técnicos para el tamaño de los datos o los cálculos a los que se puede escalar. Aquí hay una diapositiva de una presentación reciente de [Ryan Abernathey](https://github.com/rabernat) que muestra cómo la Entrada/Salida escala cuando se usa Zarr en Google Cloud Storage:

<script async class="speakerdeck-embed" data-slide="22" data-id="1621118c5987411fb55fdcf503cb331d" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>

## Optimizaciones para el almacenamiento en la nube: metadatos consolidados

Un problema con el uso del almacenamiento de objetos en la nube es que, aunque el rendimiento total de Entrada/Salida puede ser alto, la latencia involucrada en cada solicitud para leer el contenido de un objeto puede ser >100 ms, incluso cuando se lee desde nodos de computación dentro del mismo centro de datos. Esta latencia puede acumularse al leer metadatos de muchas matrices, porque en Zarr cada matriz tiene sus propios metadatos almacenados en un objeto separado.

Para solucionar este problema, la versión 2.3 agrega una función experimental para consolidar metadatos de todas las matrices y grupos dentro de una jerarquía en un solo objeto, que se puede leer una vez mediante una sola solicitud. Aunque esto no es adecuado para conjuntos de datos que cambian rápidamente, puede ser bueno para conjuntos de datos grandes que son relativamente estáticos.

Para utilizar esta función, se han agregado dos nuevas funciones de conveniencia. La función [`consolidate_metadata()`](https://zarr.readthedocs.io/en/stable/api/convenience.html#zarr.convenience.consolidate_metadata) realiza la consolidación inicial, leyendo todos los metadatos y combinándolos en un solo objeto. Una vez que haya hecho eso y haya implementado los datos en un almacén de objetos en la nube, la función [`open_consolidated()`](https://zarr.readthedocs.io/en/stable/api/convenience.html#zarr.convenience.open_consolidated) se puede utilizar para leer datos, haciendo uso de los metadatos consolidados.

La compatibilidad con la nueva función de metadatos consolidados ahora también está disponible a través de [xarray](http://xarray.pydata.org/en/stable/generated/xarray.open_zarr.html) y
[intake-xarray](https://intake-xarray.readthedocs.io/en/latest/index.html) (ver [este blog](https://www.anaconda.com/intake- Taking-the-pain-out-of-data-access/) para una introducción a intake), y muchos de los conjuntos de datos en [el catálogo de datos en la nube de Pangeo](https://pangeo-data.github.io/pangeo-datastore/) usan Zarr con metadatos consolidados.

A continuación se muestra un ejemplo de cómo abrir un conjunto de datos de Zarr desde el catálogo de datos de Pangeo mediante intake:

{% highlight python %}
import intake
cat_url = 'https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml'
cat = intake.Catalog(cat_url)
ds = cat.atmosphere.gmet_v1.to_dask()
{% endhighlight %}

...y [aquí está la entrada del catálogo subyacente](https://github.com/pangeo-data/pangeo-datastore/blob/aa3f12bcc3be9584c1a9071235874c9d6af94a4e/intake-catalogs/atmosphere.yaml#L6).

## Compatibilidad con N5

Casi al mismo tiempo que comenzaba el desarrollo de Zarr, un equipo separado dirigido por [Stephan Saafeld](https://github.com/axtimwalde) en el campus de investigación de Janelia estaba experimentando desafíos similares al almacenar y computar con grandes cantidades de datos de imágenes neuronales, y desarrolló una biblioteca de software llamada [N5](https://github.com/saalfeldlab/n5). N5 está implementado en Java, pero es muy similar a Zarr en el enfoque que adopta para almacenar metadatos y fragmentos de datos, y para desacoplar el motor de almacenamiento para permitir un uso eficiente del almacenamiento en la nube.

Hay muchos puntos en común entre Zarr y N5 y estamos trabajando juntos para unir los dos enfoques. Como primer paso experimental hacia ese objetivo, la versión Zarr 2.3 incluye un [adaptador de almacenamiento N5](https://zarr.readthedocs.io/en/stable/api/n5.html#zarr.n5.N5Store) que permite leer y escribir datos en el disco en formato N5.

## Soporte para el protocolo de búfer.

Zarr está diseñado para funcionar de manera eficiente en una variedad de sistemas de almacenamiento diferentes con diferentes latencias y ancho de banda, desde almacenes de objetos en la nube hasta memoria y disco local. En muchas de estas configuraciones, hacer un uso eficiente de la memoria local y evitar copias de memoria siempre que sea posible puede marcar una diferencia sustancial en el rendimiento. Esto es particularmente cierto dentro del paquete [Numcodecs](http://numcodecs.rtfd.io), que es un complemento de Zarr y proporciona implementaciones de códecs de compresión y filtrado como Blosc y Zstandard. Un aspecto clave para lograr menos copias de memoria ha sido aprovechar el protocolo de búfer de Python.

El [protocolo de búfer de Python] (https://docs.python.org/3/c-api/buffer.html) es una especificación sobre cómo compartir grandes bloques de memoria entre diferentes bibliotecas sin necesidad de copiar. Este protocolo ha evolucionado con el tiempo desde su introducción original en Python 2 y su posterior implementación renovada agregada en Python 3 (con soporte a Python 2.6 y 2.7). Debido a los cambios en su comportamiento de Python 2 a Python 3 y qué objetos admitían qué implementación del protocolo de búfer, fue un poco difícil aprovecharlo de manera efectiva en Zarr.

Gracias a algunos cambios internos en Zarr 2.3 y Numcodecs 0.6, el protocolo de búfer ahora es claramente compatible con Python 2/3 en ambas bibliotecas cuando se trabaja con datos. Además de mejorar el rendimiento y el manejo de la memoria, esto debería facilitar a los usuarios el desarrollo de sus propias almacenamientos, compresores y filtros para usar con Zarr. También ha reducido la cantidad de código especializado para manejar diferentes versiones de Python.

## Desarrollo futuro

Existe una creciente comunidad de interés en torno a nuevos enfoques para el almacenamiento de datos, particularmente en la nube. Por ejemplo, [Theo McCaie](https://github.com/tam203) del Met Office Informatics Lab del Reino Unido escribió recientemente una serie de blogs sobre los desafíos que implica [almacenar 200 TB de datos de modelos meteorológicos cada día](https://medium.com/informatics-lab/creating-a-data-format-for-high-momentum-datasets-a394fa48b671). Este es un espacio emocionante para trabajar y nos gustaría hacer todo lo posible para construir conexiones y compartir conocimientos e ideas entre comunidades. Hemos iniciado una [teleconferencia recurrente](https://github.com/zarr-developers/zarr/issues/315) a la que cualquiera puede unirse, y hay un nuevo [canal de gitter](https://gitter.im/zarr-developers/community) para discusiones generales.

El enfoque principal de nuestras conversaciones hasta ahora ha sido establecer el trabajo para el desarrollo de un nuevo conjunto de especificaciones que admitan las características de Zarr y N5, y proporcionen una plataforma para la exploración y el desarrollo de nuevas características, al tiempo que identifican un protocolo central mínimo que se puede implementar en una variedad de lenguajes de programación diferentes. Todavía es relativamente temprano y hay muchas preguntas abiertas que resolver, tanto en el aspecto técnico como en términos de cómo organizamos y coordinamos los esfuerzos. Sin embargo, la comunidad es muy amigable y solidaria, y cualquiera es bienvenido a participar, así que si tiene interés, considere participar.

Si desea mantenerse en contacto o contribuir a nuevos desarrollos, esté atento a los repositorios de GitHub [zarr](https://github.com/zarr-developers/zarr) y [zarr-specs](https://github.com/zarr-developers/zarr-specs) y no dude en plantear problemas o agregar comentarios si tiene alguna pregunta o idea.

## Y finalmente... SciPy!

Si vienes a SciPy este año, nos complace mucho dar una charla sobre Zarr el [día 1 de la conferencia (miércoles 10 de julio)] (https://www.eiseverywhere.com/ehome/381993). Varios miembros de la comunidad de Zarr estarán en la conferencia, y después de la conferencia se realizarán sprints en varias áreas relacionadas, incluido un sprint de Xarray el sábado. Saludenos o [envíenos un comentario sobre este reporte en github] (https://github.com/zarr-developers/zarr/issues/396) si desea conectarse y discutir algo.

----

Publicación de blog escrita por [Alistair Miles](https://github.com/alimanfoo) y [John Kirkham] (https://github.com/jakirkham).
