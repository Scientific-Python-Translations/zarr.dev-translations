---
title: Versión 2.3 de Zarr Python
date: 2019-05-23
categories: lanzamiento zarr python
layout: home
author_profile: false
sidebar:
  title: Contenido
  nav: sidebar
---

Recientemente lanzamos la versión 2.3 del [paquete Python Zarr](https://zarr.readthedocs.io/en/stable/), que implementa el protocolo Zarr para almacenar matrices tipadas N-dimensionales y está diseñado para su uso en computación distribuida y paralela. Esta publicación proporciona una descripción general de las nuevas funciones de esta versión y alguna información sobre las direcciones futuras de Zarr.

## Nuevas opciones de almacenamiento para computación distribuida y en la nube

Una característica clave del protocolo Zarr es que el sistema de almacenamiento subyacente está desacoplado de otros componentes a través de una simple interfaz llave/valor. En Python, esta interfaz corresponde a la [`interfaz MutableMapping`](https://docs.python.org/3/glossary.html#term-mapping), que es la interfaz que implementa los diccionarios de Python [`dict`](https://docs.python.org/3/library/stdtypes.html#dict). Es decir, cualquier cosa parecida a un `dict` se puede utilizar para almacenar datos de Zarr. La simplicidad de esta interfaz significa que es relativamente sencillo agregar soporte para una variedad de sistemas de almacenamiento diferentes. La versión 2.3 agrega soporte para almacenamiento usando [SQLite](https://zarr.readthedocs.io/en/stable/api/storage.html#zarr.storage.SQLiteStore), Redis, MongoDB y [Azure Blob Storage](https://zarr.readthedocs.io/en/stable/api/storage.html#zarr.storage.ABSStore).

Por ejemplo, aquí hay un código que crea una matriz usando MongoDB:

{% highlight python %}
import zarr
store = zarr.MongoDBStore('localhost')
root = zarr.group(store=store, overwrite=True)
foo = bar.create_group('foo')
bar = foo.create_dataset('bar', shape=(10000, 1000), chunks=(1000, 100))
bar[:] = 42
store.close()
{% endhighlight %}

Para hacer lo mismo pero almacenando los datos en la nube a través de Azure Blob Storage, reemplace la creación de instancias del objeto `store` con:

{% highlight python %}
store = zarr.ABSStore(container='test', account_name='foo', account_key='bar')
{% endhighlight %}

La compatibilidad con otros servicios de almacenamiento de objetos en la nube ya estaba disponible a través de otros paquetes, con Amazon S3 compatible con el paquete [s3fs](http://s3fs.readthedocs.io/en/latest/) y Google Cloud Storage compatible con el paquete [gcsfs](https://gcsfs.readthedocs.io/en/latest/). Hay más notas sobre el uso del almacenamiento en la nube disponibles en el [tutorial de Zarr](https://zarr.readthedocs.io/en/stable/tutorial.html#distributed-cloud-storage).

El atractivo del almacenamiento en la nube es que el ancho de banda total de Entrada/Salida aumenta linealmente con el tamaño de un clúster informático, por lo que no existen límites técnicos para el tamaño de los datos o los cálculos a los que se puede escalar. Aquí hay una diapositiva de una presentación reciente de [Ryan Abernathey](https://github.com/rabernat) que muestra cómo la Entrada/Salida escala cuando se usa Zarr en Google Cloud Storage:

<script async class="speakerdeck-embed" data-slide="22" data-id="1621118c5987411fb55fdcf503cb331d" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>

## Optimizaciones para el almacenamiento en la nube: metadatos consolidados

Un problema con el uso del almacenamiento de objetos en la nube es que, aunque el rendimiento total de Entrada/Salida puede ser alto, la latencia involucrada en cada solicitud para leer el contenido de un objeto puede ser >100 ms, incluso cuando se lee desde nodos de computación dentro del mismo centro de datos. Esta latencia puede acumularse al leer metadatos de muchas matrices, porque en Zarr cada matriz tiene sus propios metadatos almacenados en un objeto separado.

Para solucionar este problema, la versión 2.3 agrega una función experimental para consolidar metadatos de todas las matrices y grupos dentro de una jerarquía en un solo objeto, que se puede leer una vez mediante una sola solicitud. Aunque esto no es adecuado para conjuntos de datos que cambian rápidamente, puede ser bueno para conjuntos de datos grandes que son relativamente estáticos.

Para utilizar esta función, se han agregado dos nuevas funciones de conveniencia. La función [`consolidate_metadata()`](https://zarr.readthedocs.io/en/stable/api/convenience.html#zarr.convenience.consolidate_metadata) realiza la consolidación inicial, leyendo todos los metadatos y combinándolos en un solo objeto. Una vez que haya hecho eso y haya implementado los datos en un almacén de objetos en la nube, la función [`open_consolidated()`](https://zarr.readthedocs.io/en/stable/api/convenience.html#zarr.convenience.open_consolidated) se puede utilizar para leer datos, haciendo uso de los metadatos consolidados.

La compatibilidad con la nueva función de metadatos consolidados ahora también está disponible a través de [xarray](http://xarray.pydata.org/en/stable/generated/xarray.open_zarr.html) y
[intake-xarray](https://intake-xarray.readthedocs.io/en/latest/index.html) (ver [este blog](https://www.anaconda.com/intake- Taking-the-pain-out-of-data-access/) para una introducción a intake), y muchos de los conjuntos de datos en [el catálogo de datos en la nube de Pangeo](https://pangeo-data.github.io/pangeo-datastore/) usan Zarr con metadatos consolidados.

A continuación se muestra un ejemplo de cómo abrir un conjunto de datos de Zarr desde el catálogo de datos de Pangeo mediante intake:

{% highlight python %}
import intake
cat_url = 'https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml'
cat = intake.Catalog(cat_url)
ds = cat.atmosphere.gmet_v1.to_dask()
{% endhighlight %}

...y [aquí está la entrada del catálogo subyacente](https://github.com/pangeo-data/pangeo-datastore/blob/aa3f12bcc3be9584c1a9071235874c9d6af94a4e/intake-catalogs/atmosphere.yaml#L6).

## Compatibilidad con N5

Casi al mismo tiempo que comenzaba el desarrollo de Zarr, un equipo separado dirigido por [Stephan Saafeld](https://github.com/axtimwalde) en el campus de investigación de Janelia estaba experimentando desafíos similares al almacenar y computar con grandes cantidades de datos de imágenes neuronales, y desarrolló una biblioteca de software llamada [N5](https://github.com/saalfeldlab/n5). N5 está implementado en Java, pero es muy similar a Zarr en el enfoque que adopta para almacenar metadatos y fragmentos de datos, y para desacoplar el motor de almacenamiento para permitir un uso eficiente del almacenamiento en la nube.

Hay muchos puntos en común entre Zarr y N5 y estamos trabajando juntos para unir los dos enfoques. Como primer paso experimental hacia ese objetivo, la versión Zarr 2.3 incluye un [adaptador de almacenamiento N5](https://zarr.readthedocs.io/en/stable/api/n5.html#zarr.n5.N5Store) que permite leer y escribir datos en el disco en formato N5.

## Soporte para el protocolo de búfer.

Zarr está diseñado para funcionar de manera eficiente en una variedad de sistemas de almacenamiento diferentes con diferentes latencias y ancho de banda, desde almacenes de objetos en la nube hasta memoria y disco local. En muchas de estas configuraciones, hacer un uso eficiente de la memoria local y evitar copias de memoria siempre que sea posible puede marcar una diferencia sustancial en el rendimiento. Esto es particularmente cierto dentro del paquete [Numcodecs](http://numcodecs.rtfd.io), que es un complemento de Zarr y proporciona implementaciones de códecs de compresión y filtrado como Blosc y Zstandard. Un aspecto clave para lograr menos copias de memoria ha sido aprovechar el protocolo de búfer de Python.

El [protocolo de búfer de Python] (https://docs.python.org/3/c-api/buffer.html) es una especificación sobre cómo compartir grandes bloques de memoria entre diferentes bibliotecas sin necesidad de copiar. Este protocolo ha evolucionado con el tiempo desde su introducción original en Python 2 y su posterior implementación renovada agregada en Python 3 (con soporte a Python 2.6 y 2.7). Debido a los cambios en su comportamiento de Python 2 a Python 3 y qué objetos admitían qué implementación del protocolo de búfer, fue un poco difícil aprovecharlo de manera efectiva en Zarr.

Gracias a algunos cambios internos en Zarr 2.3 y Numcodecs 0.6, el protocolo de búfer ahora es claramente compatible con Python 2/3 en ambas bibliotecas cuando se trabaja con datos. Además de mejorar el rendimiento y el manejo de la memoria, esto debería facilitar a los usuarios el desarrollo de sus propias almacenamientos, compresores y filtros para usar con Zarr. También ha reducido la cantidad de código especializado para manejar diferentes versiones de Python.

## Future developments

There is a growing community of interest around new approaches to
storage of array-like data, particularly in the cloud. For example,
[Theo McCaie](https://github.com/tam203) from the UK Met Office
Informatics Lab recently wrote a series of blog posts about the
challenges involved in storing 200TB of "high momentum" weather model
data every
day. This
is an exciting space to be working in and we'd like to do what we can
to build connections and share knowledge and ideas between
communities. We've started a regular
teleconference
which is open to anyone to join, and there is a new gitter
channel for general
discussion.

The main focus of our conversations so far has been setting up work
towards development of a new set of specifications that support the
features of both Zarr and N5, and provide a platform for exploration
and development of new features, while also identifying a minimal core
protocol that can be implemented in a range of different programming
languages. It is still relatively early days and there are lots of
open questions to work through, both on the technical side and in
terms of how we organise and coordinate efforts. However, the
community is very friendly and supportive, and anyone is welcome to
participate, so if you have an interest please do consider getting
involved.

If you would like to stay in touch with or contribute to new
developments, keep an eye on the
[zarr](https://github.com/zarr-developers/zarr) and
[zarr-specs](https://github.com/zarr-developers/zarr-specs) GitHub
repositories, and please feel free to raise issues or add comments if
you have any questions or ideas.

## And finally... SciPy!

If you're coming to SciPy this year, we're very pleased to be giving a
talk on Zarr on day 1 of the conference (Wednesday 10
July). Several members of
the Zarr community will be at the conference, and there are sprints
going on after the conference in a number of related areas, including
an Xarray sprint on the Saturday. Please do say hi or drop us a
comment on this
issue if you'd
like to connect and discuss anything.

----

Blog post written by [Alistair Miles](https://github.com/alimanfoo)
and [John Kirkham](https://github.com/jakirkham).
